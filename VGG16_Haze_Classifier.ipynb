{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# NON ESEGUIRE SEREVE PER RIMUOVERE IMMMAGINI A CAZZO !!!!!!!!!!!!!!!\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "# Definisci il percorso della cartella\n",
        "folder_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# Ottieni la lista di tutti i file nella cartella\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Filtra i file con estensione .png\n",
        "png_files = [file for file in file_list if file.lower().endswith('.png')]\n",
        "\n",
        "print(f\"Numero totale di immagini PNG nella cartella: {len(png_files)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Definisci il percorso della nuova cartella\n",
        "new_folder_path = \"/content/drive/MyDrive/cartellaCasino/\"\n",
        "\n",
        "# Crea la nuova cartella se non esiste\n",
        "if not os.path.exists(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n",
        "\n",
        "# Ottieni la lista di tutti i file nella cartella\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Filtra i file con estensione .png\n",
        "png_files = [file for file in file_list if file.lower().endswith('.png')]\n",
        "\n",
        "# Sposta ciascun file nella nuova cartella\n",
        "for png_file in png_files:\n",
        "    source_path = os.path.join(folder_path, png_file)\n",
        "    destination_path = os.path.join(new_folder_path, png_file)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "print(f\"{len(png_files)} immagini PNG sono state spostate nella cartella 'cartellaCAsino'.\")\n"
      ],
      "metadata": {
        "id": "myyn58keU6mU",
        "outputId": "74f04ef2-68c5-4794-efaa-5077fe81f912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero totale di immagini PNG nella cartella: 0\n",
            "0 immagini PNG sono state spostate nella cartella 'cartellaCAsino'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the cartella casino folder and its contents\n",
        "shutil.rmtree(new_folder_path)"
      ],
      "metadata": {
        "id": "h1IPNAkzp_l6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEOV_XuJ5YFW"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i3cajnYA5YFb"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tqdm import tqdm\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential ,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, roc_auc_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIIhAB5I5YHa"
      },
      "source": [
        "## Google Drive connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfYIIO4K5YHb",
        "outputId": "635d7a41-576f-47d9-d28d-f11aee935033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlRMYAL6UhSl"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rakGiCg2UhSm"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Haze-Fog-suppression/classifier/\"\n",
        "\n",
        "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
        "base_path_levels = '/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/nebbia/train_A_old/'\n",
        "base_path_nohaze = '/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/nebbia/train_B_old/'\n",
        "base_path = ''\n",
        "test_path = dataset_path + 'dataset/Test/'\n",
        "val_path = dataset_path + 'dataset/Validation/'\n",
        "train_path = dataset_path + 'dataset/Train/'\n",
        "models_path = dataset_path + 'dataset/models/'\n",
        "\n",
        "# class list\n",
        "classes = ['no_haze', 'low', 'medium', 'high']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create folders for test, validation and train in the dataset folder\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "os.makedirs(train_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "lgZ2Swk_VWBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create folders for test, validation and train in the dataset folder\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "\n",
        "# create for each class the corresponding folder in the test, validation and train folders\n",
        "for cl in classes:\n",
        "    # empty the folders if they are not empty\n",
        "    #if os.path.exists(os.path.join(test_path, cl)):\n",
        "    #    shutil.rmtree(os.path.join(test_path, cl))\n",
        "    #if os.path.exists(os.path.join(val_path, cl)):\n",
        "    #    shutil.rmtree(os.path.join(val_path, cl))\n",
        "    #if os.path.exists(os.path.join(train_path, cl)):\n",
        "    #    shutil.rmtree(os.path.join(train_path, cl))\n",
        "    os.makedirs(os.path.join(test_path, cl), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_path, cl), exist_ok=True)\n",
        "    os.makedirs(os.path.join(train_path, cl), exist_ok=True)"
      ],
      "metadata": {
        "id": "0s_oUEAQWHBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get number of images for each class\n",
        "num_images = []\n",
        "for cl in classes:\n",
        "    num_images.append(len(os.listdir(os.path.join(train_path, cl))))\n",
        "\n",
        "print(num_images)"
      ],
      "metadata": {
        "id": "Wtkvb8CjhPPy",
        "outputId": "35137181-2a8b-45d8-d953-389692b5902e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2691, 2692, 2675, 2684]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy image for class low medium high"
      ],
      "metadata": {
        "id": "Wox8Yw42X30L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S--gEe0MUhSm",
        "outputId": "b01848fc-502c-4a88-b5c0-fb8e9961e4f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying images: 100%|██████████| 12600/12600 [1:34:27<00:00,  2.22it/s]\n"
          ]
        }
      ],
      "source": [
        "for img in tqdm(os.listdir(base_path_levels), desc=\"Copying images\"):\n",
        "    # get the image name\n",
        "    img_name = img.split('.')[0]\n",
        "    # get the class of the image\n",
        "    cl = img_name.split('_')[1]\n",
        "    # get the image path\n",
        "    img_path = os.path.join(base_path_levels, img)\n",
        "    # copy the image in the corresponding class folder in the test, validation and train folders\n",
        "    if rn.random() < 0.2:\n",
        "        shutil.copy(img_path, os.path.join(test_path, cl, img))\n",
        "    elif rn.random() < 0.2:\n",
        "        shutil.copy(img_path, os.path.join(val_path, cl, img))\n",
        "    else:\n",
        "        shutil.copy(img_path, os.path.join(train_path, cl, img))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy image for class no_haze"
      ],
      "metadata": {
        "id": "Bj381ZyvX9_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for img in tqdm(os.listdir(base_path_nohaze), desc=\"Copying images\"):\n",
        "    # get the image name\n",
        "    img_name = img.split('.')[0]\n",
        "    # get the class of the image\n",
        "    cl = img_name.split('_')[1]\n",
        "    if cl == 'high':\n",
        "      # create new name\n",
        "      new_name = img_name.split('_')[0]+'_no_haze.png'\n",
        "      # get the image path\n",
        "      img_path = os.path.join(base_path_nohaze, img)\n",
        "      # copy the image in the corresponding class folder in the test, validation and train folders\n",
        "      if rn.random() < 0.2:\n",
        "          shutil.copy(img_path, os.path.join(test_path, 'no_haze', new_name))\n",
        "      elif rn.random() < 0.2:\n",
        "          shutil.copy(img_path, os.path.join(val_path, 'no_haze', new_name))\n",
        "      else:\n",
        "          shutil.copy(img_path, os.path.join(train_path, 'no_haze', new_name))"
      ],
      "metadata": {
        "id": "HEEPPQaXXu-2",
        "outputId": "cda71486-5dd6-4b08-b7f4-6479a7567f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying images: 100%|██████████| 12600/12600 [15:31<00:00, 13.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check distribution"
      ],
      "metadata": {
        "id": "GjS6UkHKYbCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BrcJp6_WUhSm",
        "outputId": "01c35b54-f55e-420b-95d6-c591e73a9496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La classe no_haze contiene 831 immagini nel test set.\n",
            "La classe no_haze contiene 678 immagini nel validation set.\n",
            "La classe no_haze contiene 2691 immagini nel train set.\n",
            "La classe low contiene 827 immagini nel test set.\n",
            "La classe low contiene 681 immagini nel validation set.\n",
            "La classe low contiene 2692 immagini nel train set.\n",
            "La classe medium contiene 827 immagini nel test set.\n",
            "La classe medium contiene 698 immagini nel validation set.\n",
            "La classe medium contiene 2675 immagini nel train set.\n",
            "La classe high contiene 815 immagini nel test set.\n",
            "La classe high contiene 701 immagini nel validation set.\n",
            "La classe high contiene 2684 immagini nel train set.\n"
          ]
        }
      ],
      "source": [
        "# check if the images have been copied correctly\n",
        "\n",
        "for cl in classes:\n",
        "    print(f\"La classe {cl} contiene {len(os.listdir(os.path.join(test_path, cl)))} immagini nel test set.\")\n",
        "    print(f\"La classe {cl} contiene {len(os.listdir(os.path.join(val_path, cl)))} immagini nel validation set.\")\n",
        "    print(f\"La classe {cl} contiene {len(os.listdir(os.path.join(train_path, cl)))} immagini nel train set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JERD8JE5YHe"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "33TGEcCA5YHe",
        "outputId": "bdebf12c-4d83-4f65-8aed-14219d77d23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10742 images belonging to 4 classes.\n",
            "Found 3300 images belonging to 4 classes.\n",
            "Found 2758 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "vgg16_results_path = os.path.join(models_path, 'VGG16')\n",
        "\n",
        "def set_seed ():\n",
        "\t'''\n",
        "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
        "\t'''\n",
        "\tseed = 10\n",
        "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
        "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
        "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
        "\tnp.random.seed(seed)\n",
        "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
        "\trn.seed(seed)\n",
        "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
        "\ttf.random.set_seed(seed)\n",
        "\n",
        "# Definisci le dimensioni delle immagini\n",
        "image_size = 512\n",
        "batch_size = 16\n",
        "\n",
        "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
        "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Carica le immagini dal set di addestramento\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di test\n",
        "test_generator = data_generator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di validazione\n",
        "val_generator = data_generator.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "def show_training_and_validation_performance(history,path):\n",
        "\t'''\n",
        "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
        "\t:param history: object in which are recorded all the events\n",
        "\t'''\n",
        "\tacc = history.history['accuracy']\n",
        "\tval_acc = history.history['val_accuracy']\n",
        "\tloss = history.history['loss']\n",
        "\tval_loss = history.history['val_loss']\n",
        "\n",
        "\tepochs = range(len(acc))\n",
        "\n",
        "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "\tplt.title('Training and validation accuracy')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.figure()\n",
        "\n",
        "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "\tplt.title('Training and validation loss')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.savefig(path)\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
        "\t'''\n",
        "\tcompile_model is used to compile the current model\n",
        "\t:param model: model to compile\n",
        "\t:param optimizer: optimizer to be used\n",
        "\t:param learning_rate: learning rate parameter for the optimizer\n",
        "\t'''\n",
        "\tif optimizer == 'adam':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "\t\tmetrics=[\"accuracy\"])\n",
        "\telif optimizer == 'rmsprop':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
        "\t\t\t\t\tmetrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\n",
        "def run_model (model, type, model_name, epochs = 20, patience=5, monitor='val_loss'):\n",
        "\t'''\n",
        "\trun_model is used to run the current mode\n",
        "\t:param model: model to run\n",
        "\t:param model_name: name given to save the model\n",
        "\t:param type: type of model, CNN, VGG16, ResNet50, InceptionV3\n",
        "\t:param epochs: how many epochs to do\n",
        "\t:param patience: patience value for Early Stopping\n",
        "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
        "\t'''\n",
        "\t# local save path for the models\n",
        "\tsave_path = os.path.join(models_path, type + '/' + model_name + '.h5')\n",
        "\tcallbacks_list = [\n",
        "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
        "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
        "\t\t\t\t\t\tfilepath = save_path,\n",
        "\t\t\t\t\t\tmonitor=monitor,\n",
        "\t\t\t\t\t\tverbose=1,\n",
        "\t\t\t\t\t\tsave_best_only=False,\n",
        "            save_weights_only=False)\n",
        "\t\t\t\t\t]\n",
        "\thistory = model.fit(train_generator,\n",
        "\t\t\t\t\t\tepochs=epochs,\n",
        "\t\t\t\t\t\tvalidation_data=val_generator,\n",
        "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
        "\t# save on Drive only the best model\n",
        "\tshow_training_and_validation_performance(history,os.path.join(models_path, type + '/' + model_name + '_validation.png'))\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred, n_classes, class_labels, model_name, type):\n",
        "\n",
        "    # Converti le etichette di classe in formato binario\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_binary = lb.fit_transform(y_true)\n",
        "\n",
        "    # Calcola i tassi di FPR e TPR per ogni classe\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = metrics.roc_curve(y_true_binary[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
        "\n",
        "    plt.figure()\n",
        "    colors = ['blue', 'red', 'green', 'purple']  # Colori per le diverse classi\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve {0} ({1:0.2f}%)'.format(class_labels[i], roc_auc[i]*100))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(os.path.join(models_path, type + '/' + model_name + '_ROC.png'))\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model (model, test_generator, model_name, type):\n",
        "\t'''\n",
        "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
        "\t:param model: model to consider\n",
        "\t'''\n",
        "\tlabels_d= ['no_haze', 'low', 'medium', 'high']\n",
        "\n",
        "\t# get predictions\n",
        "\ty_score = model.predict(test_generator)\n",
        "\t# convert predictions to classes\n",
        "\ty_pred = np.argmax(y_score, axis=-1)\n",
        "\t# get true classes\n",
        "\ty_true = test_generator.classes\n",
        "\t# extract class labels\n",
        "\tclass_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "\tprint(\"Classification report: \")\n",
        "\t# create and show classification report\n",
        "\tprint(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
        "\t# save classification report\n",
        "\twith open(os.path.join(models_path, type + '/' + model_name + '_classification_report.txt'), 'w') as f:\n",
        "\t\tf.write(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
        "\n",
        "\t# create and show confusion matrix\n",
        "\tcm = confusion_matrix(y_true, y_pred)\n",
        "\tdisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\tdisp.plot(xticks_rotation=45)\n",
        "\n",
        "\t# save confusion matrix\n",
        "\tplt.savefig(os.path.join(models_path, type, model_name + '_confusion_matrix.png'), bbox_inches='tight', pad_inches=0.1)\n",
        "\tplt.show()\n",
        "\n",
        "\tplot_roc_curve(y_true, y_score, 4, class_labels, model_name, type)\n",
        "\n",
        "def clear(model):\n",
        "\tdel model\n",
        "\tK.clear_session()\n",
        "\n",
        "set_seed ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V712ExW09hZ9"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZGNlxO15YHh"
      },
      "source": [
        "## Load VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9de8ei-T5YHh",
        "outputId": "2660430a-79ad-4d78-f544-7fb7201ab0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 256, 256, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 256, 256, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 128, 128, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 128, 128, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 128, 128, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 64, 64, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 64, 64, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Carica il modello VGG16 pre-addestrato, senza l'ultimo strato fully connected\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04WaIfXZZlbm"
      },
      "source": [
        "## Experiment 1\n",
        "VGG16 + dense layer 128 neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CTa6bC69hZ-"
      },
      "outputs": [],
      "source": [
        "# Aggiungi un nuovo strato fully connected all'ultimo layer di VGG16\n",
        "inputs = keras.Input(shape=(image_size, image_size, 3))\n",
        "x = base_model(inputs)\n",
        "x = layers.Flatten()(x)\n",
        "#x = layers.Dense(128, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x) # 4 classi\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Congela i pesi del modello base, così da mantenere l'informazione appresa\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#model = keras.models.load_model(os.path.join(models_path, 'VGG16' + '/' + 'VGG16_model' + '.h5'))\n",
        "\n",
        "# Compila il modello\n",
        "compile_model(model)\n",
        "\n",
        "# Addestra il modello\n",
        "run_model(model,\"VGG16\",\"VGG16_model\")\n",
        "\n",
        "# Valuta il modello\n",
        "evaluate_model(model,test_generator,\"VGG16_model\",\"VGG16\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(os.path.join(models_path, 'VGG16' + '/' + 'VGG16_model' + '.h5'))\n",
        "\n",
        "\n",
        "# Addestra il modello\n",
        "run_model(model,\"VGG16\",\"VGG16_model\")"
      ],
      "metadata": {
        "id": "Tyxh_CQJf7A4",
        "outputId": "e7b18234-98ce-487b-e5e8-38bccdfe19d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "672/672 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.9134"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7efbc976ac69>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Addestra il modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"VGG16\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"VGG16_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-2d9b9b2768a8>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, type, model_name, epochs, patience, monitor)\u001b[0m\n\u001b[1;32m    114\u001b[0m             save_weights_only=False)\n\u001b[1;32m    115\u001b[0m \t\t\t\t\t]\n\u001b[0;32m--> 116\u001b[0;31m \thistory = model.fit(train_generator,\n\u001b[0m\u001b[1;32m    117\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}